{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIGN_NeoALTTO_MultivariateModels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpPPWM40O2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import inspect\n",
        "import sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import decomposition\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.naive_bayes import GaussianNB as NB\n",
        "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
        "from sklearn.ensemble import RandomForestClassifier as RF\n",
        "from sklearn.ensemble import AdaBoostClassifier as AB\n",
        "from sklearn.neural_network import MLPClassifier as MLP\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "##\n",
        "arm = \"Combination\" #\"Lapatinib\" #\"Trastuzumab\" \n",
        "er_status = 'ERNEGATIVE'\n",
        "methods_dict = {'logreg': LR,\n",
        "                'k_nearest_neighbour' : kNN,\n",
        "                'naive_bayes': NB, \n",
        "                'random_forest': RF,\n",
        "                'svc': SVC}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7r7rX9szT7y",
        "colab_type": "code",
        "outputId": "fba51300-8dbc-4b25-cd7f-11565b5e55ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_path = 'data/'\n",
        "# reading the data (target)\n",
        "\n",
        "if arm == \"Lapatinib\":\n",
        "  data = pd.read_csv(input_path + 'LAPATINIB_ALONE_'+er_status+'_expression_response.csv', index_col=0)\n",
        "elif arm == \"Trastuzumab\":\n",
        "  data = pd.read_csv(input_path + 'TRASTUZUMAB_ALONE_'+er_status+'_expression_response.csv', index_col=0)\n",
        "elif arm == \"Combination\":\n",
        "  data = pd.read_csv(input_path + 'LAPATINIB_IN_COMBINATION_WITH_TRASTUZUMAB_'+er_status+'_expression_response.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jw-j-HJ0rAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_var = data['response'].values\n",
        "output_var = output_var.tolist()\n",
        "input_features = data.drop(columns = 'response')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhEGb3C9AG2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVAULDrI5T3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_sortedind = np.argsort(-input_features.var().values)\n",
        "# Generating feature frames after implementing feature selection\n",
        "input_features_top10 = input_features.iloc[:,var_sortedind[0:10]]\n",
        "input_features_top30 = input_features.iloc[:,var_sortedind[0:30]]\n",
        "input_features_top100 = input_features.iloc[:,var_sortedind[0:100]]\n",
        "input_features_top500 = input_features.iloc[:,var_sortedind[0:500]]\n",
        "input_features_top2000 = input_features.iloc[:,var_sortedind[0:2000]]\n",
        "#\n",
        "# Create PCA object\n",
        "pca = decomposition.PCA(n_components=input_features.shape[0],whiten=True, random_state = 42)\n",
        "# fitting the PCA model using the training data\n",
        "pca.fit_transform(input_features)\n",
        "# generate principle components of the training data\n",
        "input_features_pca = pd.DataFrame(pca.transform(input_features))\n",
        "\n",
        "feature_dictionary = {'top10genes': input_features_top10,\n",
        "                      'top30genes': input_features_top30,\n",
        "                      'top100genes': input_features_top100,\n",
        "                      'top500genes': input_features_top500,\n",
        "                      'top2000genes': input_features_top2000,\n",
        "                      'PCs': input_features_pca,\n",
        "                      'allgenes': input_features}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afItIrDfz7YJ",
        "colab_type": "code",
        "outputId": "d5e26cd1-00fa-4f6d-b1bf-0946586ce3a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "def LOO(method, input_df, output):\n",
        "  \n",
        "  if 'random_state' in inspect.getfullargspec(method)[0]:\n",
        "    model = method(random_state = 42)\n",
        "  else:\n",
        "    model = method()\n",
        "  preds = []\n",
        "  for point_iter in range(0,len(output)):\n",
        "    input_tmp = input_df.drop(input_df.index.values[point_iter], axis = 0)\n",
        "    output_tmp = output[:point_iter] + output[point_iter+1 :]\n",
        "    model.fit(input_tmp, output_tmp)\n",
        "    preds.append(model.predict(input_df.iloc[[point_iter],:])[0])\n",
        "\n",
        "  return preds\n",
        "\n",
        "      \n",
        "\n",
        "# Create logistic regression object\n",
        "predictions_dict = {}\n",
        "\n",
        "for method_iter in methods_dict:\n",
        "  print(method_iter)\n",
        "  predictions = pd.DataFrame(columns=[*feature_dictionary] )\n",
        "\n",
        "  for feat_iter in feature_dictionary:\n",
        "    predictions[feat_iter] = LOO(method = methods_dict[method_iter],\n",
        "                                 input_df = feature_dictionary[feat_iter],\n",
        "                                 output = output_var)\n",
        "  predictions_dict[method_iter] = predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg\n",
            "k_nearest_neighbour\n",
            "naive_bayes\n",
            "random_forest\n",
            "svc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8pm8wEe0nk3",
        "colab_type": "code",
        "outputId": "f72ff5db-f97b-4128-f47e-88690d62239b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "performance = pd.DataFrame(columns=['method','features','f1','AUC-ROC', 'banalced-accuracy'])\n",
        "\n",
        "for method_iter in methods_dict:\n",
        "  print(method_iter)\n",
        "\n",
        "  for feat_iter in feature_dictionary:\n",
        "\n",
        "    perf_list = [method_iter,\n",
        "                 feat_iter,\n",
        "                 metrics.f1_score(output_var, predictions_dict[method_iter][feat_iter]),\n",
        "                 metrics.roc_auc_score(output_var, predictions_dict[method_iter][feat_iter]),\n",
        "                 metrics.balanced_accuracy_score(output_var, predictions_dict[method_iter][feat_iter])]\n",
        "\n",
        "    perf_series = pd.Series(perf_list, index = performance.columns)\n",
        "    performance = performance.append(perf_series, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logreg\n",
            "k_nearest_neighbour\n",
            "naive_bayes\n",
            "random_forest\n",
            "svc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvC274WyH2I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "performance.to_csv(input_path + arm + '_' + er_status + '_' + 'predictions.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msyJSHyJpPKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}